{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Генерация заголовков научных статей: слабый baseline",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Источник: https://github.com/bentrevett/pytorch-seq2seq",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "! pip install transformers\n! pip install sentencepiece\n! pip install rouge_score\n! pip install datasets==1.12.0\n! pip install tabulate",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-12-10T17:10:32.277534Z",
     "iopub.execute_input": "2021-12-10T17:10:32.277954Z",
     "iopub.status.idle": "2021-12-10T17:11:24.885921Z",
     "shell.execute_reply.started": "2021-12-10T17:10:32.277845Z",
     "shell.execute_reply": "2021-12-10T17:11:24.884499Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport numpy as np\nimport pandas as pd\nimport datasets\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq,\n)\n\nimport nltk",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-10T17:11:24.893334Z",
     "iopub.execute_input": "2021-12-10T17:11:24.895738Z",
     "iopub.status.idle": "2021-12-10T17:11:34.282991Z",
     "shell.execute_reply.started": "2021-12-10T17:11:24.895687Z",
     "shell.execute_reply": "2021-12-10T17:11:34.281879Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model_name = \"sshleifer/distilbart-xsum-12-3\"\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# tokenization\nencoder_max_length = 256\ndecoder_max_length = 64",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-10T17:11:34.284589Z",
     "iopub.execute_input": "2021-12-10T17:11:34.285616Z",
     "iopub.status.idle": "2021-12-10T17:12:20.174394Z",
     "shell.execute_reply.started": "2021-12-10T17:11:34.285580Z",
     "shell.execute_reply": "2021-12-10T17:12:20.173290Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_df = pd.read_csv('../input/title-generation/train.csv')\nprint(f'Shape with duplicates: {train_df.shape}')\ntrain_df.drop_duplicates(inplace=True)\nprint(f'Shape without duplicates: {train_df.shape}')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-10T17:12:20.180295Z",
     "iopub.execute_input": "2021-12-10T17:12:20.183506Z",
     "iopub.status.idle": "2021-12-10T17:12:22.919234Z",
     "shell.execute_reply.started": "2021-12-10T17:12:20.183459Z",
     "shell.execute_reply": "2021-12-10T17:12:22.917074Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "data = datasets.Dataset.from_pandas(train_df)\ndata = data.remove_columns('__index_level_0__')\n\ndef flatten(example):\n    \n    return {\n        'document': example['abstract'],\n        'summary': example['title'],\n    }\n\ndataset = data.map(flatten, remove_columns=['abstract', 'title'])\nprint(dataset.shape)\n\ntrain_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.1).values()",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-12-10T17:12:22.922219Z",
     "iopub.execute_input": "2021-12-10T17:12:22.922646Z",
     "iopub.status.idle": "2021-12-10T17:12:38.896765Z",
     "shell.execute_reply.started": "2021-12-10T17:12:22.922597Z",
     "shell.execute_reply": "2021-12-10T17:12:38.895614Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Take a look at the data\nfor k, v in data[0].items():\n    print(k)\n    print(v)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-10T17:12:38.898586Z",
     "iopub.execute_input": "2021-12-10T17:12:38.899003Z",
     "iopub.status.idle": "2021-12-10T17:12:38.906918Z",
     "shell.execute_reply.started": "2021-12-10T17:12:38.898958Z",
     "shell.execute_reply": "2021-12-10T17:12:38.905877Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n    source, target = batch[\"document\"], batch[\"summary\"]\n    source_tokenized = tokenizer(\n        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n    )\n    target_tokenized = tokenizer(\n        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n    )\n\n    batch = {k: v for k, v in source_tokenized.items()}\n    # Ignore padding in the loss\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in l]\n        for l in target_tokenized[\"input_ids\"]\n    ]\n    return batch\n\n\ntrain_data = train_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=train_data_txt.column_names,\n)\n\nvalidation_data = validation_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=validation_data_txt.column_names,\n)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-12-10T17:12:38.908686Z",
     "iopub.execute_input": "2021-12-10T17:12:38.909876Z",
     "iopub.status.idle": "2021-12-10T17:14:13.526554Z",
     "shell.execute_reply.started": "2021-12-10T17:12:38.909759Z",
     "shell.execute_reply": "2021-12-10T17:14:13.525584Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Обучение модели",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Метрики",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n\nnltk.download(\"punkt\", quiet=True)\n\nmetric = datasets.load_metric(\"rouge\")\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract a few results from ROUGE\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n\n    prediction_lens = [\n        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n    ]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-12-10T17:14:13.528630Z",
     "iopub.execute_input": "2021-12-10T17:14:13.529293Z",
     "iopub.status.idle": "2021-12-10T17:14:15.067993Z",
     "shell.execute_reply.started": "2021-12-10T17:14:13.529242Z",
     "shell.execute_reply": "2021-12-10T17:14:15.067039Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Параметры обучения",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "training_args = Seq2SeqTrainingArguments(\n    output_dir=\"results\",\n    num_train_epochs=5,\n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=4,\n    # learning_rate=3e-05,\n    warmup_steps=500,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    predict_with_generate=True,\n    logging_dir=\"logs\",\n    logging_steps=2000,\n    save_total_limit=3,\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_data,\n    eval_dataset=validation_data,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-12-10T17:14:15.069512Z",
     "iopub.execute_input": "2021-12-10T17:14:15.069953Z",
     "iopub.status.idle": "2021-12-10T17:14:22.767193Z",
     "shell.execute_reply.started": "2021-12-10T17:14:15.069907Z",
     "shell.execute_reply": "2021-12-10T17:14:22.766202Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Обучение",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "trainer.train()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-10T17:14:22.768791Z",
     "iopub.execute_input": "2021-12-10T17:14:22.769134Z",
     "iopub.status.idle": "2021-12-10T17:48:05.626489Z",
     "shell.execute_reply.started": "2021-12-10T17:14:22.769091Z",
     "shell.execute_reply": "2021-12-10T17:48:05.624818Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T17:20:33.050082Z",
     "iopub.execute_input": "2021-12-09T17:20:33.051854Z",
     "iopub.status.idle": "2021-12-09T18:02:44.745234Z",
     "shell.execute_reply.started": "2021-12-09T17:20:33.051797Z",
     "shell.execute_reply": "2021-12-09T18:02:44.744261Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T18:02:45.713468Z",
     "iopub.execute_input": "2021-12-09T18:02:45.714004Z",
     "iopub.status.idle": "2021-12-09T18:02:45.723861Z",
     "shell.execute_reply.started": "2021-12-09T18:02:45.713966Z",
     "shell.execute_reply": "2021-12-09T18:02:45.723108Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Finally, we load the parameters from our best validation loss and get our results on the test set.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def generate_summary(test_samples, model, is_get_document=False):\n    test_samples = test_samples if is_get_document else test_samples[\"document\"]\n    inputs = tokenizer(\n        test_samples,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=encoder_max_length,\n        return_tensors=\"pt\",\n    )\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    output_str = [' '.join(output_str[0].split())]\n    return outputs, output_str",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:16:44.853065Z",
     "iopub.execute_input": "2021-12-09T19:16:44.853731Z",
     "iopub.status.idle": "2021-12-09T19:16:44.864154Z",
     "shell.execute_reply.started": "2021-12-09T19:16:44.853691Z",
     "shell.execute_reply": "2021-12-09T19:16:44.861526Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ntest_samples = validation_data_txt.select(range(16))\n\nsummaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\nsummaries_after_tuning = generate_summary(test_samples, model)[1]",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from tabulate import tabulate",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T18:03:55.691235Z",
     "iopub.execute_input": "2021-12-09T18:03:55.692295Z",
     "iopub.status.idle": "2021-12-09T18:03:55.717562Z",
     "shell.execute_reply.started": "2021-12-09T18:03:55.69225Z",
     "shell.execute_reply": "2021-12-09T18:03:55.716887Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\n    tabulate(\n        zip(\n            range(len(summaries_after_tuning)),\n            summaries_after_tuning,\n            summaries_before_tuning,\n        ),\n        headers=[\"Id\", \"Summary after\", \"Summary before\"],\n    )\n)\nprint(\"\\nTarget summaries:\\n\")\nprint(\n    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n)\nprint(\"\\nSource documents:\\n\")\nprint(tabulate(list(enumerate(test_samples[\"document\"])), headers=[\"Id\", \"Document\"]))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T18:03:55.724254Z",
     "iopub.execute_input": "2021-12-09T18:03:55.731444Z",
     "iopub.status.idle": "2021-12-09T18:03:55.79408Z",
     "shell.execute_reply.started": "2021-12-09T18:03:55.7314Z",
     "shell.execute_reply": "2021-12-09T18:03:55.792537Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Делаем submission в Kaggle",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "submission_data = pd.read_csv('../input/title-generation/test.csv')\nabstracts = submission_data['abstract'].values",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:24:35.62787Z",
     "iopub.execute_input": "2021-12-09T19:24:35.628139Z",
     "iopub.status.idle": "2021-12-09T19:24:37.192908Z",
     "shell.execute_reply.started": "2021-12-09T19:24:35.628093Z",
     "shell.execute_reply": "2021-12-09T19:24:37.192166Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Объединяем тестовые данные и данные из обучения, т.к. некоторые пересекаются",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test_samples_from_train = set(train_df['abstract']).intersection(set(submission_data['abstract']))\nwtf_df = train_df[train_df['abstract'].isin(test_samples_from_train)]\nwtf_df.describe()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:24:37.201937Z",
     "iopub.execute_input": "2021-12-09T19:24:37.205668Z",
     "iopub.status.idle": "2021-12-09T19:24:37.360774Z",
     "shell.execute_reply.started": "2021-12-09T19:24:37.205621Z",
     "shell.execute_reply": "2021-12-09T19:24:37.360063Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "bugged_title = wtf_df.abstract.mode()[0]\n# https://arxiv.org/pdf/1410.0163.pdf\nwtf_df[wtf_df['abstract'] == bugged_title]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:24:37.367213Z",
     "iopub.execute_input": "2021-12-09T19:24:37.36939Z",
     "iopub.status.idle": "2021-12-09T19:24:37.391681Z",
     "shell.execute_reply.started": "2021-12-09T19:24:37.369351Z",
     "shell.execute_reply": "2021-12-09T19:24:37.389884Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "wtf_df = wtf_df[wtf_df['abstract'] != bugged_title]\nuncertain_title = wtf_df.abstract.mode()[0]\nwtf_df[wtf_df['abstract'] == uncertain_title]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:24:37.398208Z",
     "iopub.execute_input": "2021-12-09T19:24:37.398466Z",
     "iopub.status.idle": "2021-12-09T19:24:37.417328Z",
     "shell.execute_reply.started": "2021-12-09T19:24:37.398432Z",
     "shell.execute_reply": "2021-12-09T19:24:37.415969Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "wtf_df = wtf_df[wtf_df['abstract'] != uncertain_title].reset_index(drop=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:24:37.418771Z",
     "iopub.execute_input": "2021-12-09T19:24:37.419187Z",
     "iopub.status.idle": "2021-12-09T19:24:37.431746Z",
     "shell.execute_reply.started": "2021-12-09T19:24:37.419043Z",
     "shell.execute_reply": "2021-12-09T19:24:37.430496Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Генерация заголовков для тестовых данных:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from tqdm import tqdm\ntitles = []\nfor abstract in tqdm(abstracts):\n    if abstract not in wtf_df['abstract'].values:\n        _, title = generate_summary(abstract, model, True)\n        wtf_df.loc[wtf_df.shape[0]] = abstract, title",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:24:38.031752Z",
     "iopub.execute_input": "2021-12-09T19:24:38.03206Z",
     "iopub.status.idle": "2021-12-09T19:26:36.935693Z",
     "shell.execute_reply.started": "2021-12-09T19:24:38.032024Z",
     "shell.execute_reply": "2021-12-09T19:26:36.934574Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Проверяем, что wtf_df.shape НЕ совпадает с shape изначальных тестовых данных (не должно, т.к. мы выкинули дублирующиеся данные)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "wtf_df.shape[0] == submission_data.shape[0]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:26:36.937927Z",
     "iopub.execute_input": "2021-12-09T19:26:36.938236Z",
     "iopub.status.idle": "2021-12-09T19:26:36.948558Z",
     "shell.execute_reply.started": "2021-12-09T19:26:36.938198Z",
     "shell.execute_reply": "2021-12-09T19:26:36.947521Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission_df = pd.merge(submission_data, wtf_df, on='abstract', how='left')\nsubmission_df['title'].isnull().values.any()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:29:12.807998Z",
     "iopub.execute_input": "2021-12-09T19:29:12.808292Z",
     "iopub.status.idle": "2021-12-09T19:29:12.836355Z",
     "shell.execute_reply.started": "2021-12-09T19:29:12.808261Z",
     "shell.execute_reply": "2021-12-09T19:29:12.835195Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission_df.shape[0] == submission_data.shape[0]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:29:44.616021Z",
     "iopub.execute_input": "2021-12-09T19:29:44.616637Z",
     "iopub.status.idle": "2021-12-09T19:29:44.626007Z",
     "shell.execute_reply.started": "2021-12-09T19:29:44.616598Z",
     "shell.execute_reply": "2021-12-09T19:29:44.624021Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Download python script.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "! wget -q https://raw.githubusercontent.com/Samsung-IT-Academy/stepik-dl-nlp/master/task11_kaggle/create_submission.py",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:31:10.735026Z",
     "iopub.execute_input": "2021-12-09T19:31:10.735822Z",
     "iopub.status.idle": "2021-12-09T19:31:12.464301Z",
     "shell.execute_reply.started": "2021-12-09T19:31:10.735766Z",
     "shell.execute_reply": "2021-12-09T19:31:12.463201Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Generate serialized .csv",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from create_submission import generate_csv\n\nsubmission_df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\nsubmission_df.to_csv('./logs/predicted_titles.csv', index=False)\ngenerate_csv('./logs/predicted_titles.csv', './logs/kaggle_pred.csv', '../input/title-generation/vocs.pkl')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:42:03.23846Z",
     "iopub.execute_input": "2021-12-09T19:42:03.238738Z",
     "iopub.status.idle": "2021-12-09T19:42:04.206883Z",
     "shell.execute_reply.started": "2021-12-09T19:42:03.238709Z",
     "shell.execute_reply": "2021-12-09T19:42:04.206172Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!wc -l ./logs/kaggle_pred.csv",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:42:44.862315Z",
     "iopub.execute_input": "2021-12-09T19:42:44.862859Z",
     "iopub.status.idle": "2021-12-09T19:42:45.776947Z",
     "shell.execute_reply.started": "2021-12-09T19:42:44.862823Z",
     "shell.execute_reply": "2021-12-09T19:42:45.775825Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!head ./logs/kaggle_pred.csv",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-09T19:43:10.771721Z",
     "iopub.execute_input": "2021-12-09T19:43:10.772338Z",
     "iopub.status.idle": "2021-12-09T19:43:11.95951Z",
     "shell.execute_reply.started": "2021-12-09T19:43:10.772277Z",
     "shell.execute_reply": "2021-12-09T19:43:11.954015Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Генерация заголовков научных статей: слабый baseline","metadata":{}},{"cell_type":"markdown","source":"Источник: https://github.com/bentrevett/pytorch-seq2seq","metadata":{}},{"cell_type":"code","source":"! pip install transformers\n! pip install sentencepiece\n! pip install rouge_score\n! pip install datasets==1.12.0\n! pip install tabulate","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T15:18:38.32874Z","iopub.execute_input":"2021-12-09T15:18:38.329159Z","iopub.status.idle":"2021-12-09T15:19:20.881014Z","shell.execute_reply.started":"2021-12-09T15:18:38.329035Z","shell.execute_reply":"2021-12-09T15:19:20.880179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport datasets\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq,\n)\n\nimport nltk","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:19:20.883358Z","iopub.execute_input":"2021-12-09T15:19:20.883778Z","iopub.status.idle":"2021-12-09T15:19:28.302993Z","shell.execute_reply.started":"2021-12-09T15:19:20.883738Z","shell.execute_reply":"2021-12-09T15:19:28.302072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"sshleifer/distilbart-xsum-12-3\"\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set model parameters or use the default\n# print(model.config)\n\n# tokenization\nencoder_max_length = 256  # demo\ndecoder_max_length = 64","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:19:28.304429Z","iopub.execute_input":"2021-12-09T15:19:28.30538Z","iopub.status.idle":"2021-12-09T15:20:36.826328Z","shell.execute_reply.started":"2021-12-09T15:19:28.305344Z","shell.execute_reply":"2021-12-09T15:20:36.825566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = datasets.load_dataset('csv', data_files='../input/title-generation/train.csv')['train']\n\ndef flatten(example):\n    # print(example)\n    return {\n        'document': example['abstract'],\n        'summary': example['title'],\n    }\n\n# this function falls maybe because in data examples are strings, not lists\n# def list2samples(example):\n#     documents = []\n#     summaries = []\n#     for sample in zip(example['document'], example['summary']):\n#         if len(sample[0]) > 0:\n#             documents += sample[0]\n#             summaries += sample[1]\n#     return {'document': documents, 'summary': summaries}\n\n\ndataset = data.map(flatten, remove_columns=['abstract', 'title'])\n# dataset = dataset['train']\nprint(dataset.shape)\n# dataset = dataset.map(list2samples, batched=True)\n\ntrain_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.1).values()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T15:20:36.828985Z","iopub.execute_input":"2021-12-09T15:20:36.829423Z","iopub.status.idle":"2021-12-09T15:20:54.606723Z","shell.execute_reply.started":"2021-12-09T15:20:36.829384Z","shell.execute_reply":"2021-12-09T15:20:54.605996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take a look at the data\nfor k, v in data[0].items():\n    print(k)\n    print(v)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:20:54.608283Z","iopub.execute_input":"2021-12-09T15:20:54.608823Z","iopub.status.idle":"2021-12-09T15:20:54.616486Z","shell.execute_reply.started":"2021-12-09T15:20:54.608784Z","shell.execute_reply":"2021-12-09T15:20:54.615821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n    source, target = batch[\"document\"], batch[\"summary\"]\n    source_tokenized = tokenizer(\n        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n    )\n    target_tokenized = tokenizer(\n        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n    )\n\n    batch = {k: v for k, v in source_tokenized.items()}\n    # Ignore padding in the loss\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in l]\n        for l in target_tokenized[\"input_ids\"]\n    ]\n    return batch\n\n\ntrain_data = train_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=train_data_txt.column_names,\n)\n\nvalidation_data = validation_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=validation_data_txt.column_names,\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T15:20:54.617842Z","iopub.execute_input":"2021-12-09T15:20:54.618345Z","iopub.status.idle":"2021-12-09T15:22:35.868358Z","shell.execute_reply.started":"2021-12-09T15:20:54.618311Z","shell.execute_reply":"2021-12-09T15:22:35.867592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"markdown","source":"### Метрики","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n\nnltk.download(\"punkt\", quiet=True)\n\nmetric = datasets.load_metric(\"rouge\")\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract a few results from ROUGE\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n\n    prediction_lens = [\n        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n    ]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T15:22:35.869986Z","iopub.execute_input":"2021-12-09T15:22:35.870414Z","iopub.status.idle":"2021-12-09T15:22:38.978549Z","shell.execute_reply.started":"2021-12-09T15:22:35.870373Z","shell.execute_reply":"2021-12-09T15:22:38.977784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Параметры обучения","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"results\",\n    num_train_epochs=5,\n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=4,\n    # learning_rate=3e-05,\n    warmup_steps=500,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    predict_with_generate=True,\n    logging_dir=\"logs\",\n    logging_steps=2000,\n    save_total_limit=3,\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_data,\n    eval_dataset=validation_data,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T15:22:38.979871Z","iopub.execute_input":"2021-12-09T15:22:38.980184Z","iopub.status.idle":"2021-12-09T15:22:45.217979Z","shell.execute_reply.started":"2021-12-09T15:22:38.980095Z","shell.execute_reply":"2021-12-09T15:22:45.217052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Обучение","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:22:45.223353Z","iopub.execute_input":"2021-12-09T15:22:45.223702Z","iopub.status.idle":"2021-12-09T17:20:33.042446Z","shell.execute_reply.started":"2021-12-09T15:22:45.223665Z","shell.execute_reply":"2021-12-09T17:20:33.037726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:20:33.050082Z","iopub.execute_input":"2021-12-09T17:20:33.051854Z","iopub.status.idle":"2021-12-09T18:02:44.745234Z","shell.execute_reply.started":"2021-12-09T17:20:33.051797Z","shell.execute_reply":"2021-12-09T18:02:44.744261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"execution":{"iopub.status.busy":"2021-12-09T18:02:45.713468Z","iopub.execute_input":"2021-12-09T18:02:45.714004Z","iopub.status.idle":"2021-12-09T18:02:45.723861Z","shell.execute_reply.started":"2021-12-09T18:02:45.713966Z","shell.execute_reply":"2021-12-09T18:02:45.723108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we load the parameters from our best validation loss and get our results on the test set.","metadata":{}},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"### Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.","metadata":{}},{"cell_type":"code","source":"def generate_summary(test_samples, model, is_get_document=False):\n    test_samples = test_samples if is_get_document else test_samples[\"document\"]\n    inputs = tokenizer(\n        test_samples,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=encoder_max_length,\n        return_tensors=\"pt\",\n    )\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    output_str = [' '.join(output_str[0].split())]\n    return outputs, output_str","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:16:44.853065Z","iopub.execute_input":"2021-12-09T19:16:44.853731Z","iopub.status.idle":"2021-12-09T19:16:44.864154Z","shell.execute_reply.started":"2021-12-09T19:16:44.853691Z","shell.execute_reply":"2021-12-09T19:16:44.861526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ntest_samples = validation_data_txt.select(range(16))\n\nsummaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\nsummaries_after_tuning = generate_summary(test_samples, model)[1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tabulate import tabulate","metadata":{"execution":{"iopub.status.busy":"2021-12-09T18:03:55.691235Z","iopub.execute_input":"2021-12-09T18:03:55.692295Z","iopub.status.idle":"2021-12-09T18:03:55.717562Z","shell.execute_reply.started":"2021-12-09T18:03:55.69225Z","shell.execute_reply":"2021-12-09T18:03:55.716887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\n    tabulate(\n        zip(\n            range(len(summaries_after_tuning)),\n            summaries_after_tuning,\n            summaries_before_tuning,\n        ),\n        headers=[\"Id\", \"Summary after\", \"Summary before\"],\n    )\n)\nprint(\"\\nTarget summaries:\\n\")\nprint(\n    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n)\nprint(\"\\nSource documents:\\n\")\nprint(tabulate(list(enumerate(test_samples[\"document\"])), headers=[\"Id\", \"Document\"]))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T18:03:55.724254Z","iopub.execute_input":"2021-12-09T18:03:55.731444Z","iopub.status.idle":"2021-12-09T18:03:55.79408Z","shell.execute_reply.started":"2021-12-09T18:03:55.7314Z","shell.execute_reply":"2021-12-09T18:03:55.792537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Делаем submission в Kaggle","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsubmission_data = pd.read_csv('../input/title-generation/test.csv')\nabstracts = submission_data['abstract'].values\ntrain_df = pd.read_csv('../input/title-generation/train.csv')\ntrain_df.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:24:35.62787Z","iopub.execute_input":"2021-12-09T19:24:35.628139Z","iopub.status.idle":"2021-12-09T19:24:37.192908Z","shell.execute_reply.started":"2021-12-09T19:24:35.628093Z","shell.execute_reply":"2021-12-09T19:24:37.192166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Объединяем тестовые данные и данные из обучения, т.к. некоторые пересекаются","metadata":{}},{"cell_type":"code","source":"test_samples_from_train = set(train_df['abstract']).intersection(set(submission_data['abstract']))\nwtf_df = train_df[train_df['abstract'].isin(test_samples_from_train)]\nwtf_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:24:37.201937Z","iopub.execute_input":"2021-12-09T19:24:37.205668Z","iopub.status.idle":"2021-12-09T19:24:37.360774Z","shell.execute_reply.started":"2021-12-09T19:24:37.205621Z","shell.execute_reply":"2021-12-09T19:24:37.360063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bugged_title = wtf_df.abstract.mode()[0]\n# https://arxiv.org/pdf/1410.0163.pdf\nwtf_df[wtf_df['abstract'] == bugged_title]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:24:37.367213Z","iopub.execute_input":"2021-12-09T19:24:37.36939Z","iopub.status.idle":"2021-12-09T19:24:37.391681Z","shell.execute_reply.started":"2021-12-09T19:24:37.369351Z","shell.execute_reply":"2021-12-09T19:24:37.389884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wtf_df = wtf_df[wtf_df['abstract'] != bugged_title]\nuncertain_title = wtf_df.abstract.mode()[0]\nwtf_df[wtf_df['abstract'] == uncertain_title]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:24:37.398208Z","iopub.execute_input":"2021-12-09T19:24:37.398466Z","iopub.status.idle":"2021-12-09T19:24:37.417328Z","shell.execute_reply.started":"2021-12-09T19:24:37.398432Z","shell.execute_reply":"2021-12-09T19:24:37.415969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wtf_df = wtf_df[wtf_df['abstract'] != uncertain_title].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:24:37.418771Z","iopub.execute_input":"2021-12-09T19:24:37.419187Z","iopub.status.idle":"2021-12-09T19:24:37.431746Z","shell.execute_reply.started":"2021-12-09T19:24:37.419043Z","shell.execute_reply":"2021-12-09T19:24:37.430496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Генерация заголовков для тестовых данных:","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\ntitles = []\nfor abstract in tqdm(abstracts):\n    if abstract not in wtf_df['abstract'].values:\n        _, title = generate_summary(abstract, model, True)\n        wtf_df.loc[wtf_df.shape[0]] = abstract, title","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:24:38.031752Z","iopub.execute_input":"2021-12-09T19:24:38.03206Z","iopub.status.idle":"2021-12-09T19:26:36.935693Z","shell.execute_reply.started":"2021-12-09T19:24:38.032024Z","shell.execute_reply":"2021-12-09T19:26:36.934574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Проверяем, что wtf_df.shape НЕ совпадает с shape изначальных тестовых данных (не должно, т.к. мы выкинули дублирующиеся данные)","metadata":{}},{"cell_type":"code","source":"wtf_df.shape[0] == submission_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:26:36.937927Z","iopub.execute_input":"2021-12-09T19:26:36.938236Z","iopub.status.idle":"2021-12-09T19:26:36.948558Z","shell.execute_reply.started":"2021-12-09T19:26:36.938198Z","shell.execute_reply":"2021-12-09T19:26:36.947521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.merge(submission_data, wtf_df, on='abstract', how='left')\nsubmission_df['title'].isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:29:12.807998Z","iopub.execute_input":"2021-12-09T19:29:12.808292Z","iopub.status.idle":"2021-12-09T19:29:12.836355Z","shell.execute_reply.started":"2021-12-09T19:29:12.808261Z","shell.execute_reply":"2021-12-09T19:29:12.835195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.shape[0] == submission_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:29:44.616021Z","iopub.execute_input":"2021-12-09T19:29:44.616637Z","iopub.status.idle":"2021-12-09T19:29:44.626007Z","shell.execute_reply.started":"2021-12-09T19:29:44.616598Z","shell.execute_reply":"2021-12-09T19:29:44.624021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Download python script.","metadata":{}},{"cell_type":"code","source":"! wget -q https://raw.githubusercontent.com/Samsung-IT-Academy/stepik-dl-nlp/master/task11_kaggle/create_submission.py","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:31:10.735026Z","iopub.execute_input":"2021-12-09T19:31:10.735822Z","iopub.status.idle":"2021-12-09T19:31:12.464301Z","shell.execute_reply.started":"2021-12-09T19:31:10.735766Z","shell.execute_reply":"2021-12-09T19:31:12.463201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate serialized .csv","metadata":{}},{"cell_type":"code","source":"from create_submission import generate_csv\n\nsubmission_df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\nsubmission_df.to_csv('./logs/predicted_titles.csv', index=False)\ngenerate_csv('./logs/predicted_titles.csv', './logs/kaggle_pred.csv', '../input/title-generation/vocs.pkl')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:42:03.23846Z","iopub.execute_input":"2021-12-09T19:42:03.238738Z","iopub.status.idle":"2021-12-09T19:42:04.206883Z","shell.execute_reply.started":"2021-12-09T19:42:03.238709Z","shell.execute_reply":"2021-12-09T19:42:04.206172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wc -l ./logs/kaggle_pred.csv","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:42:44.862315Z","iopub.execute_input":"2021-12-09T19:42:44.862859Z","iopub.status.idle":"2021-12-09T19:42:45.776947Z","shell.execute_reply.started":"2021-12-09T19:42:44.862823Z","shell.execute_reply":"2021-12-09T19:42:45.775825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head ./logs/kaggle_pred.csv","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:43:10.771721Z","iopub.execute_input":"2021-12-09T19:43:10.772338Z","iopub.status.idle":"2021-12-09T19:43:11.95951Z","shell.execute_reply.started":"2021-12-09T19:43:10.772277Z","shell.execute_reply":"2021-12-09T19:43:11.954015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}